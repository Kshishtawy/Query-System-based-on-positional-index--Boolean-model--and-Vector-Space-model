{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1ea1281",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "451d1e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from natsort import natsorted\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "import pandas as pd\n",
    "import math\n",
    "from math import log10\n",
    "import numpy as np\n",
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1be20e",
   "metadata": {},
   "source": [
    "# First part\n",
    "\n",
    "1. Read (.txt) files [Test set of 10 files was provided for this coursework]\n",
    "2. Apply tokenization\n",
    "3. Apply stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "233c4c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_tokenization_and_stemming(text):\n",
    "    # initializing the stemmer. in our case it is the PorterStemmer\n",
    "    stemmer = PorterStemmer()\n",
    "\n",
    "    # tokenizing words\n",
    "    tokenization = word_tokenize(text)\n",
    "\n",
    "    # declearing the list of stemmed words\n",
    "    stemmed_words = []\n",
    "\n",
    "    # looping over the tokenzied words and applying stemming then appending each stemmed word to 'stemmed_words'\n",
    "    for word in tokenization:\n",
    "        stemmed_words.append(stemmer.stem(word))\n",
    "\n",
    "    # returning a list of words that are tokenized and stemmed\n",
    "    return stemmed_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80b8d6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_collection = natsorted(os.listdir('DocumentCollection'))\n",
    "\n",
    "list_of_terms = []\n",
    "\n",
    "for doc in document_collection:\n",
    "    with open(f'DocumentCollection/{doc}', 'r') as f:\n",
    "            document = f.read()\n",
    "    list_of_terms.append(apply_tokenization_and_stemming(document))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850b30b9",
   "metadata": {},
   "source": [
    "# Second part"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0537a23",
   "metadata": {},
   "source": [
    "## (1) Creating the positional index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af3a7764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting second part (1) positional index\n",
    "\n",
    "positional_index = {}\n",
    "\n",
    "for doc_id, terms in enumerate(list_of_terms, start=1):\n",
    "    for position, term in enumerate(terms, start=1):\n",
    "        # if the term doesn't exist in our positional index we add it\n",
    "        if term not in positional_index:\n",
    "              positional_index[term] = {\n",
    "                   'doc_count': 1,\n",
    "                   'docs': {doc_id: [position]}\n",
    "              }\n",
    "        # if the term already exists we do the following\n",
    "        else:\n",
    "            # first, add to the count of that term\n",
    "            positional_index[term]['doc_count'] += 1\n",
    "            # if the doc_id is new, this means we have a new document that contain the same word\n",
    "            # we add a the doc_id to our positional index along with the position of that word in that doc_id\n",
    "            if doc_id not in positional_index[term]['docs']:\n",
    "                positional_index[term]['docs'][doc_id] = [position]\n",
    "            # if the doc_id already exists, then we add the position of that term within that doc_id\n",
    "            else:\n",
    "                positional_index[term]['docs'][doc_id].append(position)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "626b5455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ['antoni', 'brutu', 'caeser', 'cleopatra', 'merci', 'worser']\n",
      "2 ['antoni', 'brutu', 'caeser', 'calpurnia']\n",
      "3 ['merci', 'worser']\n",
      "4 ['brutu', 'caeser', 'merci', 'worser']\n",
      "5 ['caeser', 'merci', 'worser']\n",
      "6 ['antoni', 'caeser', 'merci']\n",
      "7 ['angel', 'fool', 'fear', 'in', 'rush', 'to', 'tread', 'where']\n",
      "8 ['angel', 'fool', 'fear', 'in', 'rush', 'to', 'tread', 'where']\n",
      "9 ['angel', 'fool', 'in', 'rush', 'to', 'tread', 'where']\n",
      "10 ['fool', 'fear', 'in', 'rush', 'to', 'tread', 'where', 'fool']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'antoni': {'doc_count': 3, 'docs': {1: [1], 2: [1], 6: [1]}},\n",
       " 'brutu': {'doc_count': 3, 'docs': {1: [2], 2: [2], 4: [1]}},\n",
       " 'caeser': {'doc_count': 5, 'docs': {1: [3], 2: [3], 4: [2], 5: [1], 6: [2]}},\n",
       " 'cleopatra': {'doc_count': 1, 'docs': {1: [4]}},\n",
       " 'merci': {'doc_count': 5, 'docs': {1: [5], 3: [1], 4: [3], 5: [2], 6: [3]}},\n",
       " 'worser': {'doc_count': 4, 'docs': {1: [6], 3: [2], 4: [4], 5: [3]}},\n",
       " 'calpurnia': {'doc_count': 1, 'docs': {2: [4]}},\n",
       " 'angel': {'doc_count': 3, 'docs': {7: [1], 8: [1], 9: [1]}},\n",
       " 'fool': {'doc_count': 5, 'docs': {7: [2], 8: [2], 9: [2], 10: [1, 8]}},\n",
       " 'fear': {'doc_count': 3, 'docs': {7: [3], 8: [3], 10: [2]}},\n",
       " 'in': {'doc_count': 4, 'docs': {7: [4], 8: [4], 9: [3], 10: [3]}},\n",
       " 'rush': {'doc_count': 4, 'docs': {7: [5], 8: [5], 9: [4], 10: [4]}},\n",
       " 'to': {'doc_count': 4, 'docs': {7: [6], 8: [6], 9: [5], 10: [5]}},\n",
       " 'tread': {'doc_count': 4, 'docs': {7: [7], 8: [7], 9: [6], 10: [6]}},\n",
       " 'where': {'doc_count': 4, 'docs': {7: [8], 8: [8], 9: [7], 10: [7]}}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for doc_id, terms in enumerate(list_of_terms, start=1):\n",
    "     print(doc_id, terms)\n",
    "        \n",
    "positional_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f436f015",
   "metadata": {},
   "source": [
    "## (2) Computing Term Frequency (tf)\n",
    "\n",
    "Term frequency is how many times did the term appear in a document\n",
    "\n",
    "Our positional index now contain a dictionary in the following format\n",
    "\n",
    "{'term': {'doc_count': No. of docs containing term, 'docs': {doc_id: [positions]} } }\n",
    "\n",
    "Based on our positional index, term frequency can be calculated by getting the length of the\n",
    "[positions] array in doc_id. \n",
    "\n",
    "note: doc_id key holds positions that a term appeard. Multiple positions within the same doc_id is the term frequency for that doc_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "beca6bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "term_frequency = {}\n",
    "\n",
    "for term, info in positional_index.items():\n",
    "    term_frequency[term] = {}\n",
    "    for doc_id, positions in info['docs'].items():\n",
    "         term_frequency[term][f\"Doc{doc_id}\"] = len(positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bcadd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting our tf table to a pandas dataframe so we can display it\n",
    "tf_table = pd.DataFrame(term_frequency).transpose().fillna(0).astype(int)\n",
    "# sorting columns\n",
    "tf_table = tf_table[natsorted(tf_table.columns)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93dfeeb",
   "metadata": {},
   "source": [
    "## tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85f7f49e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame:\n",
      "╒═══════════╤════════╤════════╤════════╤════════╤════════╤════════╤════════╤════════╤════════╤═════════╕\n",
      "│           │   Doc1 │   Doc2 │   Doc3 │   Doc4 │   Doc5 │   Doc6 │   Doc7 │   Doc8 │   Doc9 │   Doc10 │\n",
      "╞═══════════╪════════╪════════╪════════╪════════╪════════╪════════╪════════╪════════╪════════╪═════════╡\n",
      "│ antoni    │      1 │      1 │      0 │      0 │      0 │      1 │      0 │      0 │      0 │       0 │\n",
      "├───────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼─────────┤\n",
      "│ brutu     │      1 │      1 │      0 │      1 │      0 │      0 │      0 │      0 │      0 │       0 │\n",
      "├───────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼─────────┤\n",
      "│ caeser    │      1 │      1 │      0 │      1 │      1 │      1 │      0 │      0 │      0 │       0 │\n",
      "├───────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼─────────┤\n",
      "│ cleopatra │      1 │      0 │      0 │      0 │      0 │      0 │      0 │      0 │      0 │       0 │\n",
      "├───────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼─────────┤\n",
      "│ merci     │      1 │      0 │      1 │      1 │      1 │      1 │      0 │      0 │      0 │       0 │\n",
      "├───────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼─────────┤\n",
      "│ worser    │      1 │      0 │      1 │      1 │      1 │      0 │      0 │      0 │      0 │       0 │\n",
      "├───────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼─────────┤\n",
      "│ calpurnia │      0 │      1 │      0 │      0 │      0 │      0 │      0 │      0 │      0 │       0 │\n",
      "├───────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼─────────┤\n",
      "│ angel     │      0 │      0 │      0 │      0 │      0 │      0 │      1 │      1 │      1 │       0 │\n",
      "├───────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼─────────┤\n",
      "│ fool      │      0 │      0 │      0 │      0 │      0 │      0 │      1 │      1 │      1 │       2 │\n",
      "├───────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼─────────┤\n",
      "│ fear      │      0 │      0 │      0 │      0 │      0 │      0 │      1 │      1 │      0 │       1 │\n",
      "├───────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼─────────┤\n",
      "│ in        │      0 │      0 │      0 │      0 │      0 │      0 │      1 │      1 │      1 │       1 │\n",
      "├───────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼─────────┤\n",
      "│ rush      │      0 │      0 │      0 │      0 │      0 │      0 │      1 │      1 │      1 │       1 │\n",
      "├───────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼─────────┤\n",
      "│ to        │      0 │      0 │      0 │      0 │      0 │      0 │      1 │      1 │      1 │       1 │\n",
      "├───────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼─────────┤\n",
      "│ tread     │      0 │      0 │      0 │      0 │      0 │      0 │      1 │      1 │      1 │       1 │\n",
      "├───────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼────────┼─────────┤\n",
      "│ where     │      0 │      0 │      0 │      0 │      0 │      0 │      1 │      1 │      1 │       1 │\n",
      "╘═══════════╧════════╧════════╧════════╧════════╧════════╧════════╧════════╧════════╧════════╧═════════╛\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "print(\"DataFrame:\")\n",
    "print(tabulate(tf_table, headers='keys', tablefmt='fancy_grid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6bae7838",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_tf = tf_table.copy()\n",
    "\n",
    "for c_name, c_value in w_tf.items():\n",
    "    # print(f\"Column: {c_value}\")\n",
    "    for index, value in c_value.items():\n",
    "        if w_tf.loc[index, c_name] != 0:\n",
    "            w_tf.loc[index, c_name] = (1 + log10(w_tf.loc[index, c_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f651d5",
   "metadata": {},
   "source": [
    "## w_tf(1 + log(tf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5050384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Doc1</th>\n",
       "      <th>Doc2</th>\n",
       "      <th>Doc3</th>\n",
       "      <th>Doc4</th>\n",
       "      <th>Doc5</th>\n",
       "      <th>Doc6</th>\n",
       "      <th>Doc7</th>\n",
       "      <th>Doc8</th>\n",
       "      <th>Doc9</th>\n",
       "      <th>Doc10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>antoni</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brutu</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>caeser</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cleopatra</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>merci</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worser</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calpurnia</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>angel</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fool</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.30103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fear</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rush</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tread</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>where</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Doc1  Doc2  Doc3  Doc4  Doc5  Doc6  Doc7  Doc8  Doc9    Doc10\n",
       "antoni        1     1     0     0     0     1     0     0     0  0.00000\n",
       "brutu         1     1     0     1     0     0     0     0     0  0.00000\n",
       "caeser        1     1     0     1     1     1     0     0     0  0.00000\n",
       "cleopatra     1     0     0     0     0     0     0     0     0  0.00000\n",
       "merci         1     0     1     1     1     1     0     0     0  0.00000\n",
       "worser        1     0     1     1     1     0     0     0     0  0.00000\n",
       "calpurnia     0     1     0     0     0     0     0     0     0  0.00000\n",
       "angel         0     0     0     0     0     0     1     1     1  0.00000\n",
       "fool          0     0     0     0     0     0     1     1     1  1.30103\n",
       "fear          0     0     0     0     0     0     1     1     0  1.00000\n",
       "in            0     0     0     0     0     0     1     1     1  1.00000\n",
       "rush          0     0     0     0     0     0     1     1     1  1.00000\n",
       "to            0     0     0     0     0     0     1     1     1  1.00000\n",
       "tread         0     0     0     0     0     0     1     1     1  1.00000\n",
       "where         0     0     0     0     0     0     1     1     1  1.00000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9d007b",
   "metadata": {},
   "source": [
    "## (3) Computing IDF\n",
    "\n",
    "IDF measures how rare a term is by dividing the number of documents (N) by the how many documents did the term appear in - the document frequency (df)\n",
    "\n",
    "The equation is: IDF = log_10(N/df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "029927c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>df</th>\n",
       "      <th>idf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>antoni</th>\n",
       "      <td>3</td>\n",
       "      <td>0.522879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brutu</th>\n",
       "      <td>3</td>\n",
       "      <td>0.522879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>caeser</th>\n",
       "      <td>5</td>\n",
       "      <td>0.30103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cleopatra</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>merci</th>\n",
       "      <td>5</td>\n",
       "      <td>0.30103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worser</th>\n",
       "      <td>4</td>\n",
       "      <td>0.39794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calpurnia</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>angel</th>\n",
       "      <td>3</td>\n",
       "      <td>0.522879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fool</th>\n",
       "      <td>5</td>\n",
       "      <td>0.30103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fear</th>\n",
       "      <td>3</td>\n",
       "      <td>0.522879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>4</td>\n",
       "      <td>0.39794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rush</th>\n",
       "      <td>4</td>\n",
       "      <td>0.39794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>4</td>\n",
       "      <td>0.39794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tread</th>\n",
       "      <td>4</td>\n",
       "      <td>0.39794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>where</th>\n",
       "      <td>4</td>\n",
       "      <td>0.39794</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          df       idf\n",
       "antoni     3  0.522879\n",
       "brutu      3  0.522879\n",
       "caeser     5   0.30103\n",
       "cleopatra  1       1.0\n",
       "merci      5   0.30103\n",
       "worser     4   0.39794\n",
       "calpurnia  1       1.0\n",
       "angel      3  0.522879\n",
       "fool       5   0.30103\n",
       "fear       3  0.522879\n",
       "in         4   0.39794\n",
       "rush       4   0.39794\n",
       "to         4   0.39794\n",
       "tread      4   0.39794\n",
       "where      4   0.39794"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_idf_table = pd.DataFrame(columns=['df', 'idf'])\n",
    "\n",
    "N = len(document_collection)\n",
    "\n",
    "for i, term in enumerate(positional_index):\n",
    "    df_idf_table.loc[i, 'df'] = tf_table.loc[term].sum(axis=0)\n",
    "    df_idf_table.loc[i, 'idf'] = log10(N/df_idf_table.loc[i, 'df'])\n",
    "    \n",
    "df_idf_table.index = tf_table.index\n",
    "df_idf_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40305624",
   "metadata": {},
   "source": [
    "## (4) Computing TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "157c39fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Doc1</th>\n",
       "      <th>Doc2</th>\n",
       "      <th>Doc3</th>\n",
       "      <th>Doc4</th>\n",
       "      <th>Doc5</th>\n",
       "      <th>Doc6</th>\n",
       "      <th>Doc7</th>\n",
       "      <th>Doc8</th>\n",
       "      <th>Doc9</th>\n",
       "      <th>Doc10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>antoni</th>\n",
       "      <td>0.522879</td>\n",
       "      <td>0.522879</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.522879</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brutu</th>\n",
       "      <td>0.522879</td>\n",
       "      <td>0.522879</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.522879</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>caeser</th>\n",
       "      <td>0.30103</td>\n",
       "      <td>0.30103</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.30103</td>\n",
       "      <td>0.30103</td>\n",
       "      <td>0.30103</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cleopatra</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>merci</th>\n",
       "      <td>0.30103</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.30103</td>\n",
       "      <td>0.30103</td>\n",
       "      <td>0.30103</td>\n",
       "      <td>0.30103</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worser</th>\n",
       "      <td>0.39794</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.39794</td>\n",
       "      <td>0.39794</td>\n",
       "      <td>0.39794</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calpurnia</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>angel</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.522879</td>\n",
       "      <td>0.522879</td>\n",
       "      <td>0.522879</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fool</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.30103</td>\n",
       "      <td>0.30103</td>\n",
       "      <td>0.30103</td>\n",
       "      <td>0.60206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fear</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.522879</td>\n",
       "      <td>0.522879</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.522879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.39794</td>\n",
       "      <td>0.39794</td>\n",
       "      <td>0.39794</td>\n",
       "      <td>0.39794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rush</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.39794</td>\n",
       "      <td>0.39794</td>\n",
       "      <td>0.39794</td>\n",
       "      <td>0.39794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.39794</td>\n",
       "      <td>0.39794</td>\n",
       "      <td>0.39794</td>\n",
       "      <td>0.39794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tread</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.39794</td>\n",
       "      <td>0.39794</td>\n",
       "      <td>0.39794</td>\n",
       "      <td>0.39794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>where</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.39794</td>\n",
       "      <td>0.39794</td>\n",
       "      <td>0.39794</td>\n",
       "      <td>0.39794</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Doc1      Doc2     Doc3      Doc4     Doc5      Doc6      Doc7  \\\n",
       "antoni     0.522879  0.522879      0.0       0.0      0.0  0.522879       0.0   \n",
       "brutu      0.522879  0.522879      0.0  0.522879      0.0       0.0       0.0   \n",
       "caeser      0.30103   0.30103      0.0   0.30103  0.30103   0.30103       0.0   \n",
       "cleopatra       1.0       0.0      0.0       0.0      0.0       0.0       0.0   \n",
       "merci       0.30103       0.0  0.30103   0.30103  0.30103   0.30103       0.0   \n",
       "worser      0.39794       0.0  0.39794   0.39794  0.39794       0.0       0.0   \n",
       "calpurnia       0.0       1.0      0.0       0.0      0.0       0.0       0.0   \n",
       "angel           0.0       0.0      0.0       0.0      0.0       0.0  0.522879   \n",
       "fool            0.0       0.0      0.0       0.0      0.0       0.0   0.30103   \n",
       "fear            0.0       0.0      0.0       0.0      0.0       0.0  0.522879   \n",
       "in              0.0       0.0      0.0       0.0      0.0       0.0   0.39794   \n",
       "rush            0.0       0.0      0.0       0.0      0.0       0.0   0.39794   \n",
       "to              0.0       0.0      0.0       0.0      0.0       0.0   0.39794   \n",
       "tread           0.0       0.0      0.0       0.0      0.0       0.0   0.39794   \n",
       "where           0.0       0.0      0.0       0.0      0.0       0.0   0.39794   \n",
       "\n",
       "               Doc8      Doc9     Doc10  \n",
       "antoni          0.0       0.0       0.0  \n",
       "brutu           0.0       0.0       0.0  \n",
       "caeser          0.0       0.0       0.0  \n",
       "cleopatra       0.0       0.0       0.0  \n",
       "merci           0.0       0.0       0.0  \n",
       "worser          0.0       0.0       0.0  \n",
       "calpurnia       0.0       0.0       0.0  \n",
       "angel      0.522879  0.522879       0.0  \n",
       "fool        0.30103   0.30103   0.60206  \n",
       "fear       0.522879       0.0  0.522879  \n",
       "in          0.39794   0.39794   0.39794  \n",
       "rush        0.39794   0.39794   0.39794  \n",
       "to          0.39794   0.39794   0.39794  \n",
       "tread       0.39794   0.39794   0.39794  \n",
       "where       0.39794   0.39794   0.39794  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_table = tf_table.copy()\n",
    "\n",
    "for i in range(1, tf_table.shape[1] + 1):\n",
    "    tf_idf_table[f'Doc{i}'] *= df_idf_table['idf'].values\n",
    "    \n",
    "    \n",
    "    \n",
    "tf_idf_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4462ee8",
   "metadata": {},
   "source": [
    "## Normalized length of docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2593030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Euclidean length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Doc1 length</th>\n",
       "      <td>1.373462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc2 length</th>\n",
       "      <td>1.279618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc3 length</th>\n",
       "      <td>0.498974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc4 length</th>\n",
       "      <td>0.782941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc5 length</th>\n",
       "      <td>0.582747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc6 length</th>\n",
       "      <td>0.67427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc7 length</th>\n",
       "      <td>1.195493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc8 length</th>\n",
       "      <td>1.195493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc9 length</th>\n",
       "      <td>1.075083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc10 length</th>\n",
       "      <td>1.194847</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Euclidean length\n",
       "Doc1 length          1.373462\n",
       "Doc2 length          1.279618\n",
       "Doc3 length          0.498974\n",
       "Doc4 length          0.782941\n",
       "Doc5 length          0.582747\n",
       "Doc6 length           0.67427\n",
       "Doc7 length          1.195493\n",
       "Doc8 length          1.195493\n",
       "Doc9 length          1.075083\n",
       "Doc10 length         1.194847"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_length_index = [f\"{col} length\" for col in tf_idf_table.columns]\n",
    "\n",
    "doc_length = pd.DataFrame(columns=[\"Euclidean length\"], index=doc_length_index)\n",
    "\n",
    "for c_name, c_value in tf_idf_table.items():\n",
    "    doc_length.loc[f\"{c_name} length\", \"Euclidean length\"] = math.sqrt((c_value ** 2).sum())\n",
    "\n",
    "doc_length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71767f76",
   "metadata": {},
   "source": [
    "## Normalized tf.idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d02b1bdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Doc1</th>\n",
       "      <th>Doc2</th>\n",
       "      <th>Doc3</th>\n",
       "      <th>Doc4</th>\n",
       "      <th>Doc5</th>\n",
       "      <th>Doc6</th>\n",
       "      <th>Doc7</th>\n",
       "      <th>Doc8</th>\n",
       "      <th>Doc9</th>\n",
       "      <th>Doc10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>antoni</th>\n",
       "      <td>0.380701</td>\n",
       "      <td>0.408621</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.775474</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brutu</th>\n",
       "      <td>0.380701</td>\n",
       "      <td>0.408621</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.667839</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>caeser</th>\n",
       "      <td>0.219176</td>\n",
       "      <td>0.23525</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.384486</td>\n",
       "      <td>0.51657</td>\n",
       "      <td>0.446453</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cleopatra</th>\n",
       "      <td>0.728087</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>merci</th>\n",
       "      <td>0.219176</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.603298</td>\n",
       "      <td>0.384486</td>\n",
       "      <td>0.51657</td>\n",
       "      <td>0.446453</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worser</th>\n",
       "      <td>0.289735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.797516</td>\n",
       "      <td>0.508263</td>\n",
       "      <td>0.682869</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calpurnia</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.781483</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>angel</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.437375</td>\n",
       "      <td>0.437375</td>\n",
       "      <td>0.486361</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fool</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.251804</td>\n",
       "      <td>0.251804</td>\n",
       "      <td>0.280006</td>\n",
       "      <td>0.50388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fear</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.437375</td>\n",
       "      <td>0.437375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.437611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.332867</td>\n",
       "      <td>0.332867</td>\n",
       "      <td>0.370148</td>\n",
       "      <td>0.333047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rush</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.332867</td>\n",
       "      <td>0.332867</td>\n",
       "      <td>0.370148</td>\n",
       "      <td>0.333047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.332867</td>\n",
       "      <td>0.332867</td>\n",
       "      <td>0.370148</td>\n",
       "      <td>0.333047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tread</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.332867</td>\n",
       "      <td>0.332867</td>\n",
       "      <td>0.370148</td>\n",
       "      <td>0.333047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>where</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.332867</td>\n",
       "      <td>0.332867</td>\n",
       "      <td>0.370148</td>\n",
       "      <td>0.333047</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Doc1      Doc2      Doc3      Doc4      Doc5      Doc6  \\\n",
       "antoni     0.380701  0.408621       0.0       0.0       0.0  0.775474   \n",
       "brutu      0.380701  0.408621       0.0  0.667839       0.0       0.0   \n",
       "caeser     0.219176   0.23525       0.0  0.384486   0.51657  0.446453   \n",
       "cleopatra  0.728087       0.0       0.0       0.0       0.0       0.0   \n",
       "merci      0.219176       0.0  0.603298  0.384486   0.51657  0.446453   \n",
       "worser     0.289735       0.0  0.797516  0.508263  0.682869       0.0   \n",
       "calpurnia       0.0  0.781483       0.0       0.0       0.0       0.0   \n",
       "angel           0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "fool            0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "fear            0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "in              0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "rush            0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "to              0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "tread           0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "where           0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "               Doc7      Doc8      Doc9     Doc10  \n",
       "antoni          0.0       0.0       0.0       0.0  \n",
       "brutu           0.0       0.0       0.0       0.0  \n",
       "caeser          0.0       0.0       0.0       0.0  \n",
       "cleopatra       0.0       0.0       0.0       0.0  \n",
       "merci           0.0       0.0       0.0       0.0  \n",
       "worser          0.0       0.0       0.0       0.0  \n",
       "calpurnia       0.0       0.0       0.0       0.0  \n",
       "angel      0.437375  0.437375  0.486361       0.0  \n",
       "fool       0.251804  0.251804  0.280006   0.50388  \n",
       "fear       0.437375  0.437375       0.0  0.437611  \n",
       "in         0.332867  0.332867  0.370148  0.333047  \n",
       "rush       0.332867  0.332867  0.370148  0.333047  \n",
       "to         0.332867  0.332867  0.370148  0.333047  \n",
       "tread      0.332867  0.332867  0.370148  0.333047  \n",
       "where      0.332867  0.332867  0.370148  0.333047  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_tf_idf = tf_idf_table.copy()\n",
    "\n",
    "for c_name, c_value in normalized_tf_idf.items():\n",
    "    doc_length_value = doc_length.loc[f\"{c_name} length\", \"Euclidean length\"]\n",
    "    normalized_tf_idf[c_name] = normalized_tf_idf[c_name] / doc_length_value\n",
    "\n",
    "normalized_tf_idf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae3fc8d",
   "metadata": {},
   "source": [
    "## (5) Phrase query\n",
    "\n",
    "we should apply the same preprocessing to the query as we did to our collection. In other words we should apply tokenization and stemming. This works on exact postions of the phrase query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5ef4fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersect(postings):\n",
    "    # check if postings list is empty\n",
    "    if len(postings) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        intersection_set = set(postings[0])\n",
    "\n",
    "        for posting in postings[1:]:\n",
    "            intersection_set = intersection_set.intersection(posting)\n",
    "            \n",
    "\n",
    "        return natsorted(intersection_set)\n",
    "\n",
    "def matched_docs(query):\n",
    "    query_terms = query\n",
    "    postings_list = []\n",
    "    for term in query_terms:\n",
    "        if term in positional_index:\n",
    "            postings_list.append(list(positional_index[term]['docs'].keys()))\n",
    "        else:\n",
    "            print(\"No documents found for selected query terms\")\n",
    "            return 0\n",
    "            \n",
    "    # ordering the postings list based on df (this will help with intersection)\n",
    "    ordered_postings = sorted(postings_list, key=lambda item: len(item))\n",
    "    \n",
    "    # print(ordered_postings)\n",
    "    \n",
    "    # computed matched docs with intersect function on the ordered postings\n",
    "    matched_docs = intersect(ordered_postings)\n",
    "    \n",
    "    # after looping the query_terms if no terms are matched with positional index\n",
    "    # the postings_list will be empty and return 0\n",
    "    if not (bool(matched_docs)):\n",
    "        return 0\n",
    "        \n",
    "    # else we intersect term's postings lists\n",
    "    else:\n",
    "        return matched_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec04d8da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'antoni': {1: [1], 2: [1], 6: [1]},\n",
       " 'brutu': {1: [2], 2: [2], 4: [1]},\n",
       " 'caeser': {1: [3], 2: [3], 4: [2], 5: [1], 6: [2]},\n",
       " 'cleopatra': {1: [4]},\n",
       " 'merci': {1: [5], 3: [1], 4: [3], 5: [2], 6: [3]},\n",
       " 'worser': {1: [6], 3: [2], 4: [4], 5: [3]},\n",
       " 'calpurnia': {2: [4]},\n",
       " 'angel': {7: [1], 8: [1], 9: [1]},\n",
       " 'fool': {7: [2], 8: [2], 9: [2], 10: [1, 8]},\n",
       " 'fear': {7: [3], 8: [3], 10: [2]},\n",
       " 'in': {7: [4], 8: [4], 9: [3], 10: [3]},\n",
       " 'rush': {7: [5], 8: [5], 9: [4], 10: [4]},\n",
       " 'to': {7: [6], 8: [6], 9: [5], 10: [5]},\n",
       " 'tread': {7: [7], 8: [7], 9: [6], 10: [6]},\n",
       " 'where': {7: [8], 8: [8], 9: [7], 10: [7]}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_id_positions = {key: value['docs'] for key, value in positional_index.items()}\n",
    "\n",
    "doc_id_positions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da648379",
   "metadata": {},
   "source": [
    "### this one puts term with its repective postions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2bb3769",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_query(query):\n",
    "    stemmed_query = apply_tokenization_and_stemming(query)\n",
    "    operator = \"\"\n",
    "    switch = 0\n",
    "    phrase_one = []\n",
    "    phrase_two = []\n",
    "    \n",
    "    for term in stemmed_query:\n",
    "        if switch == 0:\n",
    "            phrase_one.append(term)\n",
    "        elif switch == 1:\n",
    "            phrase_two.append(term)\n",
    "\n",
    "        if term == \"and\":\n",
    "            switch = 1\n",
    "            phrase_one.pop()\n",
    "            operator = \"and\"\n",
    "\n",
    "        elif term == \"or\":\n",
    "            switch = 1\n",
    "            phrase_one.pop()\n",
    "            operator = \"or\"\n",
    "\n",
    "        elif term == \"not\":\n",
    "            switch = 1\n",
    "            phrase_one.pop()\n",
    "            operator = \"not\"\n",
    "    return phrase_one, operator, phrase_two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "28e5b91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def phrase_query(phrase):\n",
    "    \n",
    "    list_of_docs = matched_docs(phrase)\n",
    "    \n",
    "    # matched docs for the phrase\n",
    "    if len(phrase) == 1 or len(phrase) == 0:\n",
    "        return list_of_docs\n",
    "        \n",
    "    else:\n",
    "        if list_of_docs == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            \n",
    "            #print(list_of_docs)\n",
    "            postings = []\n",
    "\n",
    "            # get the positions of matched docs for each term in query\n",
    "            for term in phrase:\n",
    "                postings_term = []\n",
    "                for i in list_of_docs:\n",
    "                    # print(doc_id_positions[term][i])\n",
    "                    postings_term.append(int(doc_id_positions[term][i][0]))\n",
    "                postings.append(postings_term)\n",
    "\n",
    "            #print(postings)\n",
    "\n",
    "            # using the 666 method\n",
    "            # postings will have same values for a successfully detected phrase\n",
    "            for index, list_of_positions in enumerate(postings):\n",
    "                for pos_idx, position in enumerate(list_of_positions):\n",
    "                    postings[index][pos_idx] = position + (len(postings) - index)\n",
    "\n",
    "\n",
    "            final_list = []\n",
    "            for index, list_of_positions in enumerate(postings):\n",
    "                for i in range(len(postings[index])):\n",
    "                    if postings[index][i] == postings[index+1][i]:\n",
    "                        final_list.append(list_of_docs[i])\n",
    "                break\n",
    "\n",
    "\n",
    "            #print(list_of_docs)\n",
    "            #print(postings)\n",
    "\n",
    "\n",
    "            return final_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c065a0e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter phrase query: antony brutus\n",
      "[1, 2]  0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['antoni', 'brutu'], [1, 2])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = input(\"Please enter phrase query: \")\n",
    "\n",
    "phrase_one, operator, phrase_two = process_query(query)\n",
    "\n",
    "def boolean_operation(phrase_one, operator, phrase_two):\n",
    "    matched_phrase1 = phrase_query(phrase_one)\n",
    "    matched_phrase2 = phrase_query(phrase_two)\n",
    "    print(matched_phrase1, operator, matched_phrase2)\n",
    "    \n",
    "    terms = []\n",
    "    result = matched_phrase1\n",
    "    \n",
    "    if bool(phrase_two) == 0:\n",
    "        if bool(result) != 0:\n",
    "            for term in phrase_one:\n",
    "                terms.append(term)\n",
    "\n",
    "            for term in phrase_two:\n",
    "                terms.append(term)\n",
    "            return terms, result\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    if operator == \"and\":\n",
    "        if bool(matched_phrase2) == 0:\n",
    "            print(\"No matched docs for current phrase query\")\n",
    "            return 0\n",
    "        else:\n",
    "            result = list(set(matched_phrase1).intersection(set(matched_phrase2)))\n",
    "            if bool(result) == 0:\n",
    "                print(\"No matched docs for current phrase query\")\n",
    "                return 0\n",
    "            else:\n",
    "                for term in phrase_one:\n",
    "                    terms.append(term)\n",
    "\n",
    "                for term in phrase_two:\n",
    "                    terms.append(term)\n",
    "                return terms, result\n",
    "\n",
    "\n",
    "    elif operator == \"or\":\n",
    "        if bool(matched_phrase2) == 0:\n",
    "            for term in phrase_one:\n",
    "                terms.append(term)\n",
    "            return terms, result\n",
    "        else:\n",
    "            for term in phrase_one:\n",
    "                terms.append(term)\n",
    "\n",
    "            for term in phrase_two:\n",
    "                terms.append(term)\n",
    "\n",
    "            for i in matched_phrase2:\n",
    "                result.append(i)\n",
    "\n",
    "            return terms, list(set(result))\n",
    "\n",
    "    elif operator == \"not\":\n",
    "        if bool(matched_phrase2) == 0:\n",
    "            for term in phrase_one:\n",
    "                terms.append(term)\n",
    "            return terms, result\n",
    "        else:\n",
    "            for i in matched_phrase2:\n",
    "                if i in result:\n",
    "                    result.remove(i)\n",
    "\n",
    "            if bool(result) == 0:\n",
    "                print(\"No matched docs for current phrase query\")\n",
    "                return 0\n",
    "            else:\n",
    "                for term in phrase_one:\n",
    "                    terms.append(term)\n",
    "                return terms, result        \n",
    "    \n",
    "\n",
    "    \n",
    "boolean_operation(phrase_one, operator, phrase_two)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1e39e9",
   "metadata": {},
   "source": [
    "## (6) Compute similarity between query and matched docs\n",
    "\n",
    "similarity between a document and a query sim(d, q) is defined by - assuming each one is an array of weight = dot_product(d, q) / euclidean_length(d, q). The result is a similary score between the document and the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a61ab2ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter phrase query: antony brutus and caeser \n",
      "[1, 2] and [1, 2, 4, 5, 6]\n",
      "[1, 2] and [1, 2, 4, 5, 6]\n",
      "0.7983880152039714\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tf-raw</th>\n",
       "      <th>tf(1 + log tf)</th>\n",
       "      <th>idf</th>\n",
       "      <th>tf*idf</th>\n",
       "      <th>Normalized</th>\n",
       "      <th>Doc1</th>\n",
       "      <th>Doc2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>antoni</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.522879</td>\n",
       "      <td>0.522879</td>\n",
       "      <td>0.654918</td>\n",
       "      <td>0.249328</td>\n",
       "      <td>0.267613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brutu</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.522879</td>\n",
       "      <td>0.522879</td>\n",
       "      <td>0.654918</td>\n",
       "      <td>0.249328</td>\n",
       "      <td>0.267613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>caeser</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.301030</td>\n",
       "      <td>0.301030</td>\n",
       "      <td>0.377047</td>\n",
       "      <td>0.082640</td>\n",
       "      <td>0.088700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sum</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.581296</td>\n",
       "      <td>0.623927</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        tf-raw  tf(1 + log tf)       idf    tf*idf  Normalized      Doc1  \\\n",
       "antoni     1.0             1.0  0.522879  0.522879    0.654918  0.249328   \n",
       "brutu      1.0             1.0  0.522879  0.522879    0.654918  0.249328   \n",
       "caeser     1.0             1.0  0.301030  0.301030    0.377047  0.082640   \n",
       "sum        NaN             NaN       NaN       NaN         NaN  0.581296   \n",
       "\n",
       "            Doc2  \n",
       "antoni  0.267613  \n",
       "brutu   0.267613  \n",
       "caeser  0.088700  \n",
       "sum     0.623927  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrase_one, operator, phrase_two = process_query(input(\"Please enter phrase query: \"))\n",
    "\n",
    "if bool(boolean_operation(phrase_one, operator, phrase_two)) != 0:\n",
    "    query_terms, query_result = boolean_operation(phrase_one, operator, phrase_two)\n",
    "else:\n",
    "    query_result = 0\n",
    "\n",
    "query_tf = {}\n",
    "if bool(query_result) == 0:\n",
    "    print(\"Not results found for query\")\n",
    "else:\n",
    "    for term in query_terms:\n",
    "        if term in query_tf:\n",
    "            query_tf[term] += 1\n",
    "        else:\n",
    "            query_tf[term] = 1\n",
    "    #print(query_tf)\n",
    "    query_stat = pd.DataFrame(columns=[\"tf-raw\", \"tf(1 + log tf)\", \"idf\", \"tf*idf\", \"Normalized\"], index=query_tf.keys())\n",
    "\n",
    "    query_stat['tf-raw'] = query_tf.values()\n",
    "    #print(query_stat)\n",
    "\n",
    "    query_stat[\"tf(1 + log tf)\"] = 1 + query_stat[\"tf-raw\"].apply(log10)\n",
    "\n",
    "    query_idf = []\n",
    "    for term in query_terms:\n",
    "        query_idf.append(float(df_idf_table.loc[term, \"idf\"]))\n",
    "\n",
    "    query_stat[\"idf\"] = query_idf\n",
    "    \n",
    "    query_stat[\"tf*idf\"] = query_stat[\"tf(1 + log tf)\"] *  query_stat[\"idf\"]\n",
    "    \n",
    "    query_length = math.sqrt((query_stat[\"tf*idf\"] **2).sum())\n",
    "    \n",
    "    print(query_length)\n",
    "    \n",
    "    query_stat[\"Normalized\"] = query_stat[\"tf*idf\"] / query_length\n",
    "    \n",
    "    for doc in query_result:\n",
    "        query_stat[f\"Doc{doc}\"] = 0\n",
    "    \n",
    "    query_stat.loc[\"sum\"] = np.nan\n",
    "    \n",
    "    for query_term in query_terms:\n",
    "        for i in range(len(query_result)):\n",
    "            #print(query_term, query_result[i])\n",
    "            query_stat.loc[query_term, f\"Doc{query_result[i]}\"] = query_stat.loc[query_term, \"Normalized\"] * normalized_tf_idf.loc[query_term, f\"Doc{query_result[i]}\"]\n",
    "               \n",
    "    for doc in query_result:\n",
    "        query_stat.loc[\"sum\", f\"Doc{doc}\"] = query_stat[f\"Doc{doc}\"].sum()\n",
    "\n",
    "\n",
    "# print(query_result)\n",
    "\n",
    "\n",
    "query_stat\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff073d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2    0.623927\n",
      "Doc1    0.581296\n",
      "Name: sum, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(pd.Series(query_stat.loc[\"sum\"].dropna().sort_values(ascending=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f7ddc2ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Doc2', 'Doc1']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sim_score(query_stat, doc):\n",
    "    doc = f\"Doc{doc}\"\n",
    "    if doc in query_stat.keys():\n",
    "        return query_stat.loc[\"sum\", doc]\n",
    "    else:\n",
    "        print(f\"There is no similarity score between the query and {doc}\")\n",
    "        \n",
    "def doc_rank(query_stat):\n",
    "    rank = pd.Series(query_stat.loc[\"sum\"].dropna().sort_values(ascending=False))\n",
    "    return list(rank.index)\n",
    "        \n",
    "sim_score(query_stat, 1)\n",
    "doc_rank(query_stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260f1934",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
